{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOW WALK ON THE USER TAG TRACE GRAPH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "PR=α⋅P⋅PR+(1−α)⋅v\n",
    "\n",
    "this is what used in the inbuilt library. for pagerank . where alpha is the damping factor.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASE: 1\n",
      "Graph loaded with 231 nodes and 4487 edges.\n",
      "PageRank computed successfully.\n",
      "Top recommendations based on PageRank:\n",
      "Node: kosaraju-algorithm, PageRank: 0.01521582209846155\n",
      "Node: recursive-backtracking, PageRank: 0.013724212428604853\n",
      "Node: longest-substring, PageRank: 0.01154506229542819\n",
      "Node: big-o, PageRank: 0.01144588473536216\n",
      "Node: strongly-connected-graph, PageRank: 0.011194739477045634\n",
      "CASE: 2\n",
      "Graph loaded with 231 nodes and 230 edges.\n",
      "PageRank computed successfully.\n",
      "Top recommendations based on PageRank:\n",
      "Node: boolean-operations, PageRank: 0.00895717289288754\n",
      "Node: binomial-heap, PageRank: 0.008470445078241379\n",
      "Node: red-black-tree-insertion, PageRank: 0.008329286889406545\n",
      "Node: kruskals-algorithm, PageRank: 0.008221430847573393\n",
      "Node: np-hard, PageRank: 0.008111633533455767\n",
      "CASE: 3\n",
      "Graph loaded with 231 nodes and 242 edges.\n",
      "PageRank computed successfully.\n",
      "Top recommendations based on PageRank:\n",
      "Node: binomial-heap, PageRank: 0.009143744857206476\n",
      "Node: branch-and-bound, PageRank: 0.009095629558014056\n",
      "Node: ternary-search, PageRank: 0.008475820536925117\n",
      "Node: boolean-operations, PageRank: 0.00844719883781316\n",
      "Node: 2-satisfiability, PageRank: 0.008166324115024921\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def read_graph(file_path):\n",
    "    try:\n",
    "        # Reading GML format\n",
    "        G = nx.read_gml(file_path, label='label')\n",
    "        print(f\"Graph loaded with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "        return G\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the graph: {e}\")\n",
    "        return nx.DiGraph()\n",
    "\n",
    "def compute_pagerank(graph, alpha=0.4):\n",
    "    try:\n",
    "        pr = nx.pagerank(graph, alpha=alpha)\n",
    "        print(\"PageRank computed successfully.\")\n",
    "        return pr\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while computing PageRank: {e}\")\n",
    "        return {}\n",
    "\n",
    "def generate_recommendations(pagerank_scores, known_nodes, top_n=5):\n",
    "    # Exclude known nodes from the PageRank scores\n",
    "    filtered_scores = {node: score for node, score in pagerank_scores.items() if node not in known_nodes}\n",
    "    \n",
    "    # Sort the PageRank scores in descending order\n",
    "    sorted_scores = sorted(filtered_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    # Get the top N recommendations\n",
    "    recommendations = sorted_scores[:top_n]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage\n",
    "file_paths = [r'D:\\IITRPRCPS\\USER_TAG_TRACE_GRAPH\\fully_connected_graph.graph',\n",
    "              r'D:\\IITRPRCPS\\USER_TAG_TRACE_GRAPH\\maximal_spanning_tree-DN.graph',\n",
    "              r'D:\\IITRPRCPS\\USER_TAG_TRACE_GRAPH\\maximal_spanning_tree-DE.graph']  # Replace with your actual file paths\n",
    "known_nodes = {'arrays'}  # Replace with the actual set of known nodes\n",
    "\n",
    "for j, file_path in enumerate(file_paths):\n",
    "    print(f\"CASE: {j+1}\")\n",
    "    G = read_graph(file_path)\n",
    "    if G.number_of_nodes() == 0:\n",
    "        print(\"Graph is empty. Skipping this file.\")\n",
    "        continue\n",
    "    pagerank_scores = compute_pagerank(G, alpha=0.75)\n",
    "    recommendations = generate_recommendations(pagerank_scores, known_nodes, top_n=5)\n",
    "\n",
    "    # Print the top N recommendations\n",
    "    print(\"Top recommendations based on PageRank:\")\n",
    "    for node, score in recommendations:\n",
    "        print(f\"Node: {node}, PageRank: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1St EXPERIMIENT:\n",
    "the graph that i got is an prerequiste kind of graph . there are different hierarchy in the graph. so inorder to recommend tags i used random walk algorithm on the graph but with few changes . here the sinkhole problem occurs then we can backtrack .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASE: 1\n",
      "Graph loaded with 231 nodes and 4487 edges.\n",
      "Top recommendations based on PageRank:\n",
      "Node: kosaraju-algorithm, PageRank: 0.01112843482518261\n",
      "Node: recursive-backtracking, PageRank: 0.009604723795514294\n",
      "Node: longest-substring, PageRank: 0.007981070941146152\n",
      "Node: strongly-connected-graph, PageRank: 0.007674607877229069\n",
      "Node: graph-coloring, PageRank: 0.007394048359299946\n",
      "CASE: 2\n",
      "Graph loaded with 231 nodes and 230 edges.\n",
      "Top recommendations based on PageRank:\n",
      "Node: binomial-heap, PageRank: 0.003683236580031438\n",
      "Node: edmonds-karp, PageRank: 0.003613977272497515\n",
      "Node: branch-and-bound, PageRank: 0.003595295810394316\n",
      "Node: tree-search, PageRank: 0.003595295810394316\n",
      "Node: ternary-search-tree, PageRank: 0.0032200624999770243\n",
      "CASE: 3\n",
      "Graph loaded with 231 nodes and 242 edges.\n",
      "Top recommendations based on PageRank:\n",
      "Node: quadratic-probing, PageRank: 0.004132511639835858\n",
      "Node: ternary-search, PageRank: 0.00405166262672061\n",
      "Node: 2-satisfiability, PageRank: 0.003929527387732551\n",
      "Node: branch-and-bound, PageRank: 0.003909602309718276\n",
      "Node: binomial-heap, PageRank: 0.003810004032019413\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def read_graph(file_path):\n",
    "    try:\n",
    "        # Reading GML format\n",
    "        G = nx.read_gml(file_path, label='label')\n",
    "        print(f\"Graph loaded with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "        return G\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the graph: {e}\")\n",
    "        return nx.DiGraph()\n",
    "\n",
    "def compute_custom_pagerank(graph, start_nodes, alpha=0.85, max_iter=100, tol=1.0e-6):\n",
    "    N = len(graph)\n",
    "    if N == 0:\n",
    "        return {}\n",
    "\n",
    "    # Initialize the PageRank dictionary\n",
    "    pagerank = {node: 0.0 for node in graph}\n",
    "    for start_node in start_nodes:\n",
    "        if start_node in graph:\n",
    "            pagerank[start_node] = 1.0 / len(start_nodes)  # Start from the specified nodes\n",
    "\n",
    "    # Personalization vector\n",
    "    p = {node: 1 / N for node in graph}\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        prev_pagerank = pagerank.copy()\n",
    "        for node in graph:\n",
    "            rank_sum = sum(prev_pagerank[neighbor] / len(graph[neighbor]) for neighbor in graph.predecessors(node))\n",
    "            pagerank[node] = (1 - alpha) * p[node] + alpha * rank_sum\n",
    "\n",
    "            # Handling sink nodes\n",
    "            if len(graph[node]) == 0:  # If there are no outgoing edges\n",
    "                pagerank[node] += (1 - alpha) / N\n",
    "        \n",
    "        # Check for convergence\n",
    "        diff = sum(abs(pagerank[node] - prev_pagerank[node]) for node in pagerank)\n",
    "        if diff < tol:\n",
    "            break\n",
    "\n",
    "    return pagerank\n",
    "\n",
    "def generate_recommendations(pagerank_scores, known_nodes, top_n=5):\n",
    "    # Exclude known nodes from the PageRank scores\n",
    "    filtered_scores = {node: score for node, score in pagerank_scores.items() if node not in known_nodes}\n",
    "    \n",
    "    # Sort the PageRank scores in descending order\n",
    "    sorted_scores = sorted(filtered_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    # Get the top N recommendations\n",
    "    recommendations = sorted_scores[:top_n]\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example usage\n",
    "file_paths = [r'D:\\IITRPRCPS\\USER_TAG_TRACE_GRAPH\\fully_connected_graph.graph',\n",
    "              r'D:\\IITRPRCPS\\USER_TAG_TRACE_GRAPH\\maximal_spanning_tree-DN.graph',\n",
    "              r'D:\\IITRPRCPS\\USER_TAG_TRACE_GRAPH\\maximal_spanning_tree-DE.graph']  # Replace with your actual file paths\n",
    "known_nodes = {'arrays', 'hash', 'tree'}  # Replace with the actual set of known nodes\n",
    "\n",
    "for j, file_path in enumerate(file_paths):\n",
    "    print(f\"CASE: {j+1}\")\n",
    "    G = read_graph(file_path)\n",
    "    if G.number_of_nodes() == 0:\n",
    "        print(\"Graph is empty. Skipping this file.\")\n",
    "        continue\n",
    "    \n",
    "    start_nodes = ['arrays']  # Start from the specified nodes\n",
    "    pagerank_scores = compute_custom_pagerank(G, start_nodes=start_nodes, alpha=0.75)\n",
    "    recommendations = generate_recommendations(pagerank_scores, known_nodes, top_n=5)\n",
    "\n",
    "    # Print the top N recommendations\n",
    "    print(\"Top recommendations based on PageRank:\")\n",
    "    for node, score in recommendations:\n",
    "        print(f\"Node: {node}, PageRank: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
